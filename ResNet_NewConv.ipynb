{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "torch.cuda.set_device(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convolutional block\n",
    "# A single layer of convolution if shortcut == False, and...\n",
    "# Two layers of convolution and a residual convolution otherwise.\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inChannels, midChannels, outChannels, \n",
    "                 kernelSize, stride = 1, padding = 0, bias = True, shortcut = False):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, midChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(midChannels),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Conv2d(midChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = midChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inChannels, outChannels, \n",
    "                          kernelSize, stride, padding, groups = inChannels, bias = bias),\n",
    "                nn.BatchNorm2d(outChannels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fully connected block\n",
    "# A single layer if shortcut == False, and...\n",
    "# Two layers and a residual layer otherwise.\n",
    "\n",
    "class FCBlock(nn.Module):\n",
    "    \n",
    "    # midChannels will be of no use if shortcut == False\n",
    "    def __init__(self, inNodes, midNodes, outNodes, shortcut = False):\n",
    "        super(FCBlock, self).__init__()\n",
    "        if shortcut is False:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            self.right = None\n",
    "        else:\n",
    "            self.left = nn.Sequential(\n",
    "                nn.Linear(inNodes, midNodes),\n",
    "                nn.ReLU(inplace = True),\n",
    "                nn.Linear(midNodes, outNodes)\n",
    "            )\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Linear(inNodes, outNodes)\n",
    "            )\n",
    "            \n",
    "    def forward(self, input):\n",
    "        out = self.left(input)\n",
    "        if self.right is not None:\n",
    "            out += self.right(input)\n",
    "        return F.relu(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from the given index list. \n",
    "    \"\"\"\n",
    "    def __init__(self, index_list):\n",
    "        self.index = index_list\n",
    "        self.length = len(index_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpuDtype = torch.cuda.FloatTensor\n",
    "\n",
    "trainList = []\n",
    "valList = []\n",
    "def checkAccuracy(model, trainLoader, valLoader):\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in trainLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    trainList.append(acc)\n",
    "    print('Train: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    for x, y in valLoader:\n",
    "        with torch.no_grad():\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            scores = model(xVar)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "            numCorrect += (preds == y).sum()\n",
    "            numSamples += preds.size(0)\n",
    "    acc = float(numCorrect) / numSamples\n",
    "    valList.append(acc)\n",
    "    print('Val: %d / %d correct (%.2f%%)' % (numCorrect, numSamples, 100 * acc))\n",
    "    \n",
    "def train(model, lossFunc, optimizer, numEpochs = 1, \n",
    "          lpReg = {}, lambdaFCB = 0.0, lambdaConvB = 0.0,\n",
    "          printEvery = 100, checkEveryEpoch = True):\n",
    "    for epoch in range(numEpochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, numEpochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainLoader):\n",
    "            xVar = Variable(x.type(gpuDtype))\n",
    "            yVar = Variable(y.type(gpuDtype).long())\n",
    "            scores = model(xVar)            \n",
    "            loss = lossFunc(scores, yVar)\n",
    "            \n",
    "            weights = {}\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'bias' not in name:\n",
    "                    #print(name)\n",
    "                    #print(param)\n",
    "                    weights[name] = param \n",
    "                    for (p, lamb) in lpReg.items():\n",
    "                        loss += lamb * (torch.norm(param, int(p)) ** int(p))\n",
    "                        \n",
    "            if abs(lambdaFCB) > 1e-9:\n",
    "                FCB1WF1dotWS = weights['blocks.5.left.0.weight'].mm(weights['blocks.5.right.0.weight'].t())\n",
    "                FCB2WF1dotWS = weights['blocks.6.left.0.weight'].mm(weights['blocks.6.right.0.weight'].t())\n",
    "                loss += lambdaFCB * torch.norm(FCB1WF1dotWS, 2)\n",
    "                loss += lambdaFCB * torch.norm(FCB2WF1dotWS, 2)\n",
    "            \n",
    "#             print('Before: %f' % loss)\n",
    "            if abs(lambdaConvB) > 1e-9:\n",
    "                Conv_11 = 0.0\n",
    "                Conv_12 = 0.0\n",
    "                Conv_21 = 0.0\n",
    "                Conv_22 = 0.0\n",
    "\n",
    "                for i in range(9):\n",
    "                    for j in range(3):\n",
    "                        tmp = weights['blocks.0.left.0.weight'][i]-weights['blocks.0.right.0.weight'][i*3+j]\n",
    "                        Conv_11 += torch.norm(tmp,2)\n",
    "                for i in range(27):\n",
    "                    tmp = weights['blocks.0.left.3.weight'][i]-weights['blocks.0.right.0.weight'][i]\n",
    "                    Conv_12 += torch.norm(tmp,2)\n",
    "\n",
    "                for i in range(81):\n",
    "                    for j in range(3):\n",
    "                        tmp = weights['blocks.2.left.0.weight'][i]-weights['blocks.2.right.0.weight'][i*3+j]\n",
    "                        Conv_22 += torch.norm(tmp,2)\n",
    "                for i in range(243):\n",
    "                    tmp = weights['blocks.2.left.3.weight'][j]-weights['blocks.2.right.0.weight'][i]\n",
    "                    Conv_22 += torch.norm(tmp,2)\n",
    "\n",
    "                loss += lambdaConvB * (Conv_11 + Conv_12 + Conv_21 / 9 + Conv_22 /9) \n",
    "#             print('After: %f' %  loss)\n",
    "            if printEvery > 0 and (t + 1) % printEvery == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if checkEveryEpoch:\n",
    "            checkAccuracy(model, trainLoader, valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFigure(markLast = 0):\n",
    "    fig = plt.figure(figsize = (15, 8))\n",
    "    NUM_EPOCHS = len(trainList)\n",
    "    pt, = plt.plot(range(1, NUM_EPOCHS + 1), trainList, c = 'red')\n",
    "    pv, = plt.plot(range(1, NUM_EPOCHS + 1), valList, c = 'blue')\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        plt.text(i + 1, trainList[i] + ((i % 2) - 0.8) * 0.005, '%.4f' % trainList[i], ha = 'center', va = 'bottom', fontsize = 9)\n",
    "        plt.text(i + 1, valList[i] + ((i % 2) - 0.8) * 0.005, '%.4f' % valList[i], ha = 'center', va = 'bottom', fontsize = 9)\n",
    "        if markLast > 0 and (i == NUM_EPOCHS - markLast or i == NUM_EPOCHS - 1):\n",
    "            plt.axvline(x = i + 1, color = 'green', linewidth = 2)\n",
    "        else:\n",
    "            plt.axvline(x = i + 1, color = 'lightgrey', linewidth = 1, linestyle = '--')\n",
    "    plt.xticks(range(1, NUM_EPOCHS + 1))\n",
    "    plt.legend([pt, pv], ['Train', 'Val'], loc = 'upper left')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "def showDeltaAcc(numEpochs):\n",
    "    deltaAcc = 0.0\n",
    "    avgValAcc = 0.0\n",
    "    totalEpochs = len(trainList)\n",
    "    for i in range(totalEpochs - numEpochs, totalEpochs):\n",
    "        deltaAcc += trainList[i] - valList[i]\n",
    "        avgValAcc += valList[i]\n",
    "    deltaAcc /= numEpochs\n",
    "    avgValAcc /= numEpochs\n",
    "    print('Delta accuracy of the last %d epochs is: %.4f' % (numEpochs, deltaAcc))\n",
    "    print('Average validation accuracy of the last %d epochs is: %.4f' % (numEpochs, avgValAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ConvBlock(inChannels = 3, midChannels = 9, outChannels = 27, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            ConvBlock(inChannels = 27, midChannels = 81, outChannels = 243, \n",
    "                      kernelSize = 3, padding = 1, shortcut = True),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "            \n",
    "            Flatten(),\n",
    "            FCBlock(inNodes = 15552, midNodes = 2592, outNodes = 432, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 432, midNodes = 72, outNodes = 24, \n",
    "                    shortcut = True),\n",
    "            FCBlock(inNodes = 24, midNodes = 0, outNodes = 10, \n",
    "                    shortcut = False)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        out = self.blocks(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 50000\n",
    "\n",
    "numTrain = 20000\n",
    "numVal = 1000\n",
    "\n",
    "#random.seed(666)\n",
    "index_all = random.sample(range(DATASET_SIZE), numTrain + numVal)\n",
    "index_train = index_all[ : numTrain]\n",
    "index_val = index_all[numTrain : ]\n",
    "\n",
    "trainData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, \n",
    "                              sampler = ChunkSampler(index_train))\n",
    "        \n",
    "valData = datasets.CIFAR10('./data', train = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "valLoader = DataLoader(valData, batch_size = 64, \n",
    "                            sampler = ChunkSampler(index_val))\n",
    "\n",
    "testData = datasets.CIFAR10('./data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "testLoader = DataLoader(testData, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 50\n",
      "Train: 7105 / 20000 correct (35.52%)\n",
      "Val: 337 / 1000 correct (33.70%)\n",
      "Starting epoch 2 / 50\n",
      "Train: 9434 / 20000 correct (47.17%)\n",
      "Val: 429 / 1000 correct (42.90%)\n",
      "Starting epoch 3 / 50\n",
      "Train: 10258 / 20000 correct (51.29%)\n",
      "Val: 459 / 1000 correct (45.90%)\n",
      "Starting epoch 4 / 50\n",
      "Train: 10218 / 20000 correct (51.09%)\n",
      "Val: 457 / 1000 correct (45.70%)\n",
      "Starting epoch 5 / 50\n",
      "Train: 10741 / 20000 correct (53.71%)\n",
      "Val: 464 / 1000 correct (46.40%)\n",
      "Starting epoch 6 / 50\n",
      "Train: 11046 / 20000 correct (55.23%)\n",
      "Val: 460 / 1000 correct (46.00%)\n",
      "Starting epoch 7 / 50\n",
      "Train: 11236 / 20000 correct (56.18%)\n",
      "Val: 456 / 1000 correct (45.60%)\n",
      "Starting epoch 8 / 50\n",
      "Train: 11229 / 20000 correct (56.15%)\n",
      "Val: 450 / 1000 correct (45.00%)\n",
      "Starting epoch 9 / 50\n",
      "Train: 12418 / 20000 correct (62.09%)\n",
      "Val: 474 / 1000 correct (47.40%)\n",
      "Starting epoch 10 / 50\n",
      "Train: 12561 / 20000 correct (62.80%)\n",
      "Val: 477 / 1000 correct (47.70%)\n",
      "Starting epoch 11 / 50\n",
      "Train: 12469 / 20000 correct (62.34%)\n",
      "Val: 467 / 1000 correct (46.70%)\n",
      "Starting epoch 12 / 50\n",
      "Train: 12192 / 20000 correct (60.96%)\n",
      "Val: 464 / 1000 correct (46.40%)\n",
      "Starting epoch 13 / 50\n",
      "Train: 12853 / 20000 correct (64.27%)\n",
      "Val: 477 / 1000 correct (47.70%)\n",
      "Starting epoch 14 / 50\n",
      "Train: 12873 / 20000 correct (64.37%)\n",
      "Val: 480 / 1000 correct (48.00%)\n",
      "Starting epoch 15 / 50\n",
      "Train: 12474 / 20000 correct (62.37%)\n",
      "Val: 461 / 1000 correct (46.10%)\n",
      "Starting epoch 16 / 50\n",
      "Train: 12634 / 20000 correct (63.17%)\n",
      "Val: 459 / 1000 correct (45.90%)\n",
      "Starting epoch 17 / 50\n",
      "Train: 12788 / 20000 correct (63.94%)\n",
      "Val: 458 / 1000 correct (45.80%)\n",
      "Starting epoch 18 / 50\n",
      "Train: 12806 / 20000 correct (64.03%)\n",
      "Val: 471 / 1000 correct (47.10%)\n",
      "Starting epoch 19 / 50\n",
      "Train: 12605 / 20000 correct (63.02%)\n",
      "Val: 466 / 1000 correct (46.60%)\n",
      "Starting epoch 20 / 50\n",
      "Train: 12803 / 20000 correct (64.02%)\n",
      "Val: 462 / 1000 correct (46.20%)\n",
      "Starting epoch 21 / 50\n",
      "Train: 12936 / 20000 correct (64.68%)\n",
      "Val: 473 / 1000 correct (47.30%)\n",
      "Starting epoch 22 / 50\n",
      "Train: 13358 / 20000 correct (66.79%)\n",
      "Val: 499 / 1000 correct (49.90%)\n",
      "Starting epoch 23 / 50\n",
      "Train: 13220 / 20000 correct (66.10%)\n",
      "Val: 477 / 1000 correct (47.70%)\n",
      "Starting epoch 24 / 50\n",
      "Train: 13261 / 20000 correct (66.31%)\n",
      "Val: 477 / 1000 correct (47.70%)\n",
      "Starting epoch 25 / 50\n",
      "Train: 13257 / 20000 correct (66.29%)\n",
      "Val: 468 / 1000 correct (46.80%)\n",
      "Starting epoch 26 / 50\n",
      "Train: 12971 / 20000 correct (64.85%)\n",
      "Val: 453 / 1000 correct (45.30%)\n",
      "Starting epoch 27 / 50\n",
      "Train: 12751 / 20000 correct (63.75%)\n",
      "Val: 451 / 1000 correct (45.10%)\n",
      "Starting epoch 28 / 50\n",
      "Train: 13102 / 20000 correct (65.51%)\n",
      "Val: 450 / 1000 correct (45.00%)\n",
      "Starting epoch 29 / 50\n",
      "Train: 13343 / 20000 correct (66.72%)\n",
      "Val: 462 / 1000 correct (46.20%)\n",
      "Starting epoch 30 / 50\n",
      "Train: 13409 / 20000 correct (67.05%)\n",
      "Val: 471 / 1000 correct (47.10%)\n",
      "Starting epoch 31 / 50\n",
      "Train: 13357 / 20000 correct (66.79%)\n",
      "Val: 474 / 1000 correct (47.40%)\n",
      "Starting epoch 32 / 50\n",
      "Train: 13314 / 20000 correct (66.57%)\n",
      "Val: 461 / 1000 correct (46.10%)\n",
      "Starting epoch 33 / 50\n",
      "Train: 13114 / 20000 correct (65.57%)\n",
      "Val: 463 / 1000 correct (46.30%)\n",
      "Starting epoch 34 / 50\n",
      "Train: 13052 / 20000 correct (65.26%)\n",
      "Val: 463 / 1000 correct (46.30%)\n",
      "Starting epoch 35 / 50\n",
      "Train: 13226 / 20000 correct (66.13%)\n",
      "Val: 472 / 1000 correct (47.20%)\n",
      "Starting epoch 36 / 50\n",
      "Train: 12391 / 20000 correct (61.96%)\n",
      "Val: 445 / 1000 correct (44.50%)\n",
      "Starting epoch 37 / 50\n",
      "Train: 12818 / 20000 correct (64.09%)\n",
      "Val: 460 / 1000 correct (46.00%)\n",
      "Starting epoch 38 / 50\n",
      "Train: 12527 / 20000 correct (62.63%)\n",
      "Val: 459 / 1000 correct (45.90%)\n",
      "Starting epoch 39 / 50\n",
      "Train: 13433 / 20000 correct (67.16%)\n",
      "Val: 478 / 1000 correct (47.80%)\n",
      "Starting epoch 40 / 50\n",
      "Train: 13426 / 20000 correct (67.13%)\n",
      "Val: 477 / 1000 correct (47.70%)\n",
      "Starting epoch 41 / 50\n",
      "Train: 13448 / 20000 correct (67.24%)\n",
      "Val: 495 / 1000 correct (49.50%)\n",
      "Starting epoch 42 / 50\n",
      "Train: 13503 / 20000 correct (67.52%)\n",
      "Val: 476 / 1000 correct (47.60%)\n",
      "Starting epoch 43 / 50\n",
      "Train: 13480 / 20000 correct (67.40%)\n",
      "Val: 475 / 1000 correct (47.50%)\n",
      "Starting epoch 44 / 50\n",
      "Train: 13527 / 20000 correct (67.64%)\n",
      "Val: 492 / 1000 correct (49.20%)\n",
      "Starting epoch 45 / 50\n",
      "Train: 13544 / 20000 correct (67.72%)\n",
      "Val: 479 / 1000 correct (47.90%)\n",
      "Starting epoch 46 / 50\n",
      "Train: 13500 / 20000 correct (67.50%)\n",
      "Val: 479 / 1000 correct (47.90%)\n",
      "Starting epoch 47 / 50\n",
      "Train: 13459 / 20000 correct (67.30%)\n",
      "Val: 492 / 1000 correct (49.20%)\n",
      "Starting epoch 48 / 50\n",
      "Train: 13507 / 20000 correct (67.53%)\n",
      "Val: 476 / 1000 correct (47.60%)\n",
      "Starting epoch 49 / 50\n",
      "Train: 13491 / 20000 correct (67.45%)\n",
      "Val: 476 / 1000 correct (47.60%)\n",
      "Starting epoch 50 / 50\n"
     ]
    }
   ],
   "source": [
    "#TORCH_SEED = 666\n",
    "#torch.manual_seed(TORCH_SEED)\n",
    "#torch.cuda.manual_seed(TORCH_SEED)\n",
    "\n",
    "model = ResNet().type(gpuDtype)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "lpReg = {'2':1e-4}\n",
    "train(model, criterion, optimizer, numEpochs = 50,\n",
    "      lpReg = lpReg, lambdaFCB = 0.0, lambdaConvB = -1e-4,\n",
    "      printEvery = 0, checkEveryEpoch = True)\n",
    "\n",
    "showDeltaAcc(numEpochs = 10)\n",
    "showFigure(markLast = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
